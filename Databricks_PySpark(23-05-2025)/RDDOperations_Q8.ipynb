{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31e010c-72b3-422a-8b93-5e45432bbc7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatMap result: ['Hello', 'world', 'Spark', 'is', 'fun', 'Learn', 'PySpark']\nmap result: [('Hello', 1), ('world', 1), ('Spark', 1), ('is', 1), ('fun', 1), ('Learn', 1), ('PySpark', 1)]\nfilter result: [('Hello', 1), ('world', 1), ('Spark', 1), ('Learn', 1), ('PySpark', 1)]\njoin result: [('Hello', (1, 'greeting')), ('Spark', (1, 'framework')), ('world', (1, 'global'))]\nreduceByKey result: [('Hello', 1), ('Spark', 1), ('fun', 1), ('Learn', 1), ('world', 1), ('is', 1), ('PySpark', 1)]\ngroupByKey result: [('Hello', [1]), ('Spark', [1]), ('fun', [1]), ('Learn', [1]), ('world', [1]), ('is', [1]), ('PySpark', [1])]\nOut[4]: '\\nExplanation : parallelize: Distributes the input list across the Spark cluster.\\nflatMap: Transforms each element into multiple elements (e.g., splits “Hello world” into [“Hello”, “world”]).\\nmap: Transforms each element into a new form (e.g., (word, 1) pairs).\\nfilter: Keeps elements meeting a condition (e.g., word length > 4).\\njoin: Combines two RDDs based on keys.\\nreduceByKey: Aggregates values for each key (efficient for large data).\\ngroupByKey: Groups all values for each key (less efficient due to shuffling).\\n'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"RDDOperations\").getOrCreate()\n",
    "\n",
    "# Create an RDD using parallelize\n",
    "data = [\"Hello world\", \"Spark is fun\", \"Learn PySpark\"]\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "# 1. flatMap: Split each string into words\n",
    "flat_rdd = rdd.flatMap(lambda x: x.split())\n",
    "\n",
    "# 2. map: Create (word, 1) pairs for counting\n",
    "mapped_rdd = flat_rdd.map(lambda x: (x, 1))\n",
    "\n",
    "# 3. filter: Keep words with length > 4\n",
    "filtered_rdd = mapped_rdd.filter(lambda x: len(x[0]) > 4)\n",
    "\n",
    "# 4. Create another RDD for join\n",
    "data2 = [(\"Hello\", \"greeting\"), (\"Spark\", \"framework\"), (\"world\", \"global\")]\n",
    "rdd2 = spark.sparkContext.parallelize(data2)\n",
    "joined_rdd = mapped_rdd.join(rdd2)\n",
    "\n",
    "# 5. reduceByKey: Count word occurrences\n",
    "word_counts = mapped_rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# 6. groupByKey: Group words (less efficient, for demonstration)\n",
    "grouped_rdd = mapped_rdd.groupByKey().mapValues(list)\n",
    "\n",
    "# Collect and display results\n",
    "print(\"flatMap result:\", flat_rdd.collect())\n",
    "print(\"map result:\", mapped_rdd.collect())\n",
    "print(\"filter result:\", filtered_rdd.collect())\n",
    "print(\"join result:\", joined_rdd.collect())\n",
    "print(\"reduceByKey result:\", word_counts.collect())\n",
    "print(\"groupByKey result:\", grouped_rdd.collect())\n",
    "\n",
    "'''\n",
    "Explanation : parallelize: Distributes the input list across the Spark cluster.\n",
    "flatMap: Transforms each element into multiple elements (e.g., splits “Hello world” into [“Hello”, “world”]).\n",
    "map: Transforms each element into a new form (e.g., (word, 1) pairs).\n",
    "filter: Keeps elements meeting a condition (e.g., word length > 4).\n",
    "join: Combines two RDDs based on keys.\n",
    "reduceByKey: Aggregates values for each key (efficient for large data).\n",
    "groupByKey: Groups all values for each key (less efficient due to shuffling).\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "RDDOperations_Q8",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}